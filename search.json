[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "#Assignments\n\n#getwd()\nrandom_vars &lt;- readRDS(\"data/random_vars.rds\")\n#View(random_vars)\n\nx1_mean &lt;- mean(random_vars$age)\nx1_var &lt;- var(random_vars$age)\nx1_sd &lt;- sd(random_vars$age)\n\nx2_mean &lt;- mean(random_vars$income)\nx2_var &lt;- var(random_vars$income)\nx2_sd &lt;- sd(random_vars$income)\n\nprint(x1_mean)\n\n#&gt; [1] 33.471\n\nprint(x1_var)\n\n#&gt; [1] 340.6078\n\nprint(x1_sd)\n\n#&gt; [1] 18.45556\n\nprint(x2_mean)\n\n#&gt; [1] 3510.731\n\nprint(x2_var)\n\n#&gt; [1] 8625646\n\nprint(x2_sd)\n\n#&gt; [1] 2936.945\n\n\nComparing the standard deviations can make sense, as it is a measure of the spread (dispersion) of a random variable. In this case, the dispersion of the income is much larger than the dispersion of age, as would be expected.\n\ncovariance &lt;- cov(random_vars$age, random_vars$income)\ncorrelation &lt;- cor(random_vars$age, random_vars$income)\n\ncat(\"Covariance: \", covariance, \"\\n\")\n\n#&gt; Covariance:  29700.15\n\ncat(\"Correlation: \", correlation, \"\\n\")\n\n#&gt; Correlation:  0.5479432\n\n\nThe correlation is easier to interpret as it is unit-less (between -1 and +1). A correlation of around 0.55 implies a positive, somewhat linear relationship between the two random variables.\n\nsubset_minors &lt;- subset(random_vars, age &lt;= 18)\nsubset_adults &lt;- subset(random_vars, age &gt;= 18 & age &lt;= 65)\nsubset_seniors &lt;- subset(random_vars, age &gt;= 65)\n\nmean_minors &lt;- mean(subset_minors$income)\nmean_adults &lt;- mean(subset_adults$income)\nmean_seniors &lt;- mean(subset_seniors$income)\n\nprint(mean_minors)\n\n#&gt; [1] 389.6074\n\nprint(mean_adults)\n\n#&gt; [1] 4691.378\n\nprint(mean_seniors)\n\n#&gt; [1] 1777.237"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "1 Spurious correlation\nData taken from https://tylervigen.com/spurious-correlations (accessed 25.12.23)\n\n#Data taken from https://tylervigen.com/spurious-correlations (accessed 25.12.23)\n\nyear &lt;- c(1999:2009)\ncars_sold &lt;- c(758, 863, 837, 930, 830, 810, 923, 1154, 1183, 1142, 829)\ncars_sold &lt;- cars_sold / 10\nsuicides &lt;- c(87, 103, 91, 112, 104, 108, 113, 137, 131, 129, 104)\n\ndf &lt;- data.frame(year, cars_sold, suicides)\n\nggplot(df, aes(x = year)) + \n  geom_line(aes(y = cars_sold, color = \"Cars sold (in ten-thousands)\")) +\n  geom_line(aes(y = suicides, color = \"Suicides\")) +\n  labs(title = \"Japanese passenger cars sold in the US vs. \\n number of suicides by crashing of motor vehicle\",\n       x = \"Year\",\n       y = \"Count\") +\n  scale_color_manual(values = c(\"Cars sold (in ten-thousands)\" = \"blue\", \"Suicides\" = \"red\")) +\n  theme_minimal()"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "df &lt;- readRDS(\"data/rand_enc.rds\")\n\niv_rand_enc &lt;- dagify(\n  Y ~ D,\n  Y ~ U,\n  D ~ U,\n  D ~ Z,\n  exposure = \"D\",\n  latent = \"U\",\n  outcome = \"Y\",\n  coords = list(x = c(U = 1, D = 0, Y = 2, Z = -1),\n                y = c(U = 1, D = 0, Y = 0, Z = 0)),\n  labels = c(\"D\" = \"Used new feature\", \n             \"Y\" = \"Time spent on app\", \n             \"U\" = \"Unobserved characteristics\",\n             \"Z\" = \"Random encouragement\")\n)\nggdag(iv_rand_enc, text = T) +\n  guides(color = \"none\") +\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"white\") +\n  geom_dag_label_repel(aes(label = label))"
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "1 Assignment 1\n\ndf &lt;- readRDS((\"data/membership.rds\"))\n\ndag_model &lt;- 'dag {\nbb=\"0,0,1,1\"\nCard [exposure,pos=\"0.075,0.4\"]\nAvg_purch [outcome,pos=\"0.4,0.4\"]\nAge [pos=\"0.1,0.2\"]\nSex [pos=\"0.35,0.2\"]\nPre_avg_purch [pos=\"0.2,0.6\"]\nCard -&gt; Avg_purch\nPre_avg_purch -&gt; Avg_purch\nPre_avg_purch -&gt; Card\nAge -&gt; Card\nAge -&gt; Pre_avg_purch\nSex -&gt; Card\nSex -&gt; Pre_avg_purch\n}\n'\n# draw DAG\nggdag_status(dag_model) +\n  guides(fill = \"none\", color = \"none\") +  # Disable the legend\n  geom_dag_edges(edge_color = \"white\")\n\n\n\n\n\n\n\n\n\n\n2 Assignment 2\nPlease find the model summary at the end of this document.\n\n#model &lt;- lm(avg_purch ~ card + pre_avg_purch + age + sex, data = df)\nmodel &lt;- lm(avg_purch ~ card, data = df)\nsummary(model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -101.515  -20.684   -0.199   20.424  120.166 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  65.9397     0.3965  166.29   &lt;2e-16 ***\n#&gt; card         25.2195     0.6095   41.38   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 30.11 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.1462, Adjusted R-squared:  0.1461 \n#&gt; F-statistic:  1712 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n3 Assignment 3\n\ncem &lt;- matchit(card ~ pre_avg_purch + age + sex,\n               data = df, \n               method = 'cem', \n               estimand = 'ATE')\n#summary(cem)\ndf_cem = match.data(cem)\nmodel_cem &lt;- lm(avg_purch ~ card, data = df_cem, weights = weights)\nsummary(model_cem)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = df_cem, weights = weights)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -159.349  -20.459   -0.151   19.863  161.528 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  69.9896     0.3984  175.66   &lt;2e-16 ***\n#&gt; card         15.2043     0.6137   24.77   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 30.12 on 9878 degrees of freedom\n#&gt; Multiple R-squared:  0.0585, Adjusted R-squared:  0.0584 \n#&gt; F-statistic: 613.7 on 1 and 9878 DF,  p-value: &lt; 2.2e-16\n\nnn &lt;- matchit(card ~ pre_avg_purch + age + sex,\n              data = df,\n              method = \"nearest\",\n              distance = \"mahalanobis\",\n              replace = T)\n#summary(nn)\ndf_nn &lt;- match.data(nn)\nmodel_nn &lt;- lm(avg_purch ~ card, data = df_nn, weights = weights)\nsummary(model_nn)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = df_nn, weights = weights)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -132.730  -21.288   -1.675   18.318  146.631 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  76.5634     0.5881  130.19   &lt;2e-16 ***\n#&gt; card         14.5957     0.7514   19.42   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 30.43 on 6907 degrees of freedom\n#&gt; Multiple R-squared:  0.05179,    Adjusted R-squared:  0.05166 \n#&gt; F-statistic: 377.3 on 1 and 6907 DF,  p-value: &lt; 2.2e-16\n\nmodel_prop &lt;- glm(card ~ pre_avg_purch + age + sex,\n                  data = df,\n                  family = binomial(link = \"logit\"))\n#summary(model_prop)\ndf_aug &lt;- df %&gt;% mutate(propensity = predict(model_prop, type = \"response\"))\n\n# Extend data by IPW scores\ndf_ipw &lt;- df_aug %&gt;% mutate(\n  ipw = (card/propensity) + ((1-card) / (1-propensity)))\n\n\nmodel_ipw &lt;- lm(avg_purch ~ card,\n                data = df_ipw, \n                weights = ipw)\nsummary(model_ipw)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = df_ipw, weights = ipw)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -205.353  -28.995   -0.275   28.787  214.307 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  70.2628     0.4320  162.66   &lt;2e-16 ***\n#&gt; card         14.9573     0.6109   24.48   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 43.19 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.05657,    Adjusted R-squared:  0.05647 \n#&gt; F-statistic: 599.5 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\nmodel_ipw_trim &lt;- lm(avg_purch ~ card,\n                     data = df_ipw %&gt;% filter(propensity %&gt;% between(0.15, 0.85)),\n                     weights = ipw)\nsummary(model_ipw_trim)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = df_ipw %&gt;% filter(propensity %&gt;% \n#&gt;     between(0.15, 0.85)), weights = ipw)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -205.353  -28.995   -0.275   28.787  214.307 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  70.2628     0.4320  162.66   &lt;2e-16 ***\n#&gt; card         14.9573     0.6109   24.48   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 43.19 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.05657,    Adjusted R-squared:  0.05647 \n#&gt; F-statistic: 599.5 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\nmodelsummary::modelsummary(list(\"Naive\" = model,\n                                \"CEM\"  = model_cem,\n                                \"NN\"    = model_nn,\n                                \"IPW1\"  = model_ipw,\n                                \"IPW2\"  = model_ipw_trim))\n\n\n\n\n\nNaive\nCEM\nNN\n IPW1\n IPW2\n\n\n\n\n(Intercept)\n65.940\n69.990\n76.563\n70.263\n70.263\n\n\n\n(0.397)\n(0.398)\n(0.588)\n(0.432)\n(0.432)\n\n\ncard\n25.220\n15.204\n14.596\n14.957\n14.957\n\n\n\n(0.610)\n(0.614)\n(0.751)\n(0.611)\n(0.611)\n\n\nNum.Obs.\n10000\n9880\n6909\n10000\n10000\n\n\nR2\n0.146\n0.058\n0.052\n0.057\n0.057\n\n\nR2 Adj.\n0.146\n0.058\n0.052\n0.056\n0.056\n\n\nAIC\n96483.2\n95595.0\n67134.2\n97072.1\n97072.1\n\n\nBIC\n96504.8\n95616.6\n67154.7\n97093.7\n97093.7\n\n\nLog.Lik.\n-48238.590\n-47794.497\n-33564.098\n-48533.031\n-48533.031\n\n\nRMSE\n30.11\n30.08\n30.17\n30.54\n30.54"
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "1 Assignment 1\n\n# Confounder\nconfounding &lt;- dagify(\n  X ~ Z,\n  Y ~ Z,\n  Y ~ X,\n  coords = list(x = c(Y = 3, Z = 2, X = 1),\n                y = c(Y = 0, Z = 1, X = 0)),\n  labels = list(X = \"Parking spot available\",\n                Y = \"Sales\",\n                Z = \"Customers\")\n)\n\n# Plot DAG\nggdag(confounding) +\n  #geom_dag_point(color = ggthemr::swatch()[2]) +\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"white\") +\n  geom_dag_label_repel(aes(label = label))\n\n\n\n\n\n\n\n\n\n\n2 Assignment 2\n\ndf &lt;- readRDS(\"data/customer_sat.rds\")\nstr(df)\n\n#&gt; tibble [15 × 3] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ follow_ups  : num [1:15] 8 7 8 9 10 6 7 6 8 8 ...\n#&gt;  $ satisfaction: num [1:15] 40 45 47 44 50 55 60 62 59 65 ...\n#&gt;  $ subscription: chr [1:15] \"Elite\" \"Elite\" \"Elite\" \"Elite\" ...\n\ndf\n\n\n\n  \n\n\nmodel1 &lt;- lm(satisfaction ~ follow_ups, data = df)\nsummary(model1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\nmodel2 &lt;- lm(satisfaction ~ follow_ups + subscription, data = df)\nsummary(model2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n\n\n3 Assignment 3\nThe estimated coefficient for the number of follow-up calls is negative, meaning the satisfaction is expected to decrease if the customer receives more calls. However, this appears to originate from the connection between the number of follow-up calls and the subscription model.\nThe estimated coefficient for the number of follow-up calls while accounting for the subscription model is positive, meaning that the satisfaction is expected to increase with the number of calls while within a given subscription model.\nThis could be indicative of the fact that the customer might be experiencing more issues and problems with the software for more expensive subscription models (while also having higher expectations?). The data still suggests that making more follow-up calls will result in a higher customer satisfaction.\n\n\n4 Assignment 4\n\nsatisfaction_not_cond &lt;- ggplot(df, aes(x = follow_ups, y = satisfaction)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = F)\n\n# Conditioning on student  \nsatisfaction_cond &lt;- ggplot(df, aes(x = follow_ups, y = satisfaction,\n                            color = subscription, \n                            alpha = subscription)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = F) +\n  scale_color_manual(values = c(\"Elite\" = \"red\",\n                                \"Premium+\" = \"blue\",\n                                \"Premium\" = \"green\")) +\n  scale_alpha_manual(values = c(\"Elite\" = 1, \"Premium+\" = 0.6, \"Premium\" = 0.2)) +\n  theme(legend.position = \"right\")\n\n\nsatisfaction_not_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsatisfaction_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "1 Assignment 1\n\ndf &lt;- readRDS((\"data/abtest_online.rds\"))\n\nstr(df)\n\n#&gt; tibble [1,000 × 6] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ ip             : chr [1:1000] \"161.88.211.70\" \"239.86.201.0\" \"35.90.22.130\" \"219.176.193.3\" ...\n#&gt;  $ chatbot        : logi [1:1000] TRUE TRUE TRUE FALSE TRUE TRUE ...\n#&gt;  $ previous_visit : num [1:1000] 0 1 1 4 1 2 1 1 1 0 ...\n#&gt;  $ mobile_device  : logi [1:1000] FALSE FALSE FALSE TRUE FALSE FALSE ...\n#&gt;  $ purchase       : num [1:1000] 0 1 0 0 0 0 1 1 0 0 ...\n#&gt;  $ purchase_amount: num [1:1000] 0 39.5 0 0 0 ...\n\ncompare_device &lt;- ggplot(df, aes(x = chatbot, y = after_stat(count), fill = mobile_device)) +\n  stat_count(geom = \"bar\", position = \"dodge\") +\n  labs(x = \"Chatbot\", y = \"Number of users\", title = \"Number of users on mobile devices\") +\n  scale_fill_manual(values = c(\"FALSE\" = \"blue\", \"TRUE\" = \"red\")) +\n  theme_minimal()\n\ncompare_previous &lt;- \n  ggplot(df, \n         aes(x = chatbot, \n             y = previous_visit, \n             color = as.factor(chatbot))) +\n  stat_summary(geom = \"errorbar\", \n               width = .5,\n               fun.data = \"mean_se\", \n               fun.args = list(mult=1.96),\n               show.legend = F) +\n  labs(x = NULL, y = \"Previous visits\", title = \"Difference in previous visits\")\n\ncompare_device\n\n\n\n\n\n\n\ncompare_previous\n\n\n\n\n\n\n\nmean_previous_visits &lt;- df %&gt;%\n  group_by(chatbot) %&gt;%\n  summarize(mean_previous_visits = mean(previous_visit))\n\nprint(mean_previous_visits)\n\n#&gt; # A tibble: 2 × 2\n#&gt;   chatbot mean_previous_visits\n#&gt;   &lt;lgl&gt;                  &lt;dbl&gt;\n#&gt; 1 FALSE                   2.17\n#&gt; 2 TRUE                    1.88\n\n\nI would argue the covariates are somewhat balanced across the groups, as can be seen from the plots. However, there is a slight difference in the number of previous visits (mean 2.17 vs. 1.88).\n\n\n2 Assignment 2\n\nmodel_purchase_amount &lt;- lm(purchase_amount ~ chatbot, data = df)\nsummary(model_purchase_amount)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -16.702 -14.478  -9.626  13.922  64.648 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  16.7017     0.8374  19.944  &lt; 2e-16 ***\n#&gt; chatbotTRUE  -7.0756     1.1796  -5.998 2.79e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.65 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.0348, Adjusted R-squared:  0.03383 \n#&gt; F-statistic: 35.98 on 1 and 998 DF,  p-value: 2.787e-09\n\n\n\n\n3 Assignment 3\n\nmodel_purchase_mobile &lt;- lm(purchase_amount ~ chatbot * mobile_device, data = df)\nsummary(model_purchase_mobile)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot * mobile_device, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -16.98 -14.54  -9.95  14.13  65.24 \n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)                    16.9797     1.0152  16.725   &lt;2e-16 ***\n#&gt; chatbotTRUE                    -7.0301     1.4284  -4.922    1e-06 ***\n#&gt; mobile_deviceTRUE              -0.8727     1.7987  -0.485    0.628    \n#&gt; chatbotTRUE:mobile_deviceTRUE  -0.1526     2.5369  -0.060    0.952    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.66 on 996 degrees of freedom\n#&gt; Multiple R-squared:  0.03534,    Adjusted R-squared:  0.03244 \n#&gt; F-statistic: 12.16 on 3 and 996 DF,  p-value: 8.034e-08\n\n\n\n\n4 Assignment 4\n\nmodel_purchase &lt;- glm(purchase ~ chatbot, family=binomial(link='logit'), data = df)\nsummary(model_purchase)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = purchase ~ chatbot, family = binomial(link = \"logit\"), \n#&gt;     data = df)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -0.01613    0.08981  -0.180    0.857    \n#&gt; chatbotTRUE -0.98939    0.13484  -7.337 2.18e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1329.1  on 999  degrees of freedom\n#&gt; Residual deviance: 1273.3  on 998  degrees of freedom\n#&gt; AIC: 1277.3\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\nThe coefficient for the presence of the chatbot (-0,989) indicates that the probability of making a sale is drastically reduced (multiplied by exp(-0.989) = 0.3719485)."
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "1 Assignment 1\n\ndf &lt;- readRDS(\"data/hospdd.rds\")\nstr(df)\n\n#&gt; tibble [7,368 × 5] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ hospital : num [1:7368] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;   ..- attr(*, \"label\")= chr \"Hospital ID\"\n#&gt;   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#&gt;  $ frequency: 'int' num [1:7368] 3 2 4 2 1 1 2 4 2 2 ...\n#&gt;   ..- attr(*, \"label\")= chr \"Hospital visit frequency\"\n#&gt;   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#&gt;   ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n#&gt;   .. ..- attr(*, \"names\")= chr [1:4] \"Low\" \"Medium\" \"High\" \"Very high\"\n#&gt;  $ month    : 'int' num [1:7368] 7 3 2 4 3 7 4 1 3 1 ...\n#&gt;   ..- attr(*, \"label\")= chr \"Month\"\n#&gt;   ..- attr(*, \"format.stata\")= chr \"%8.0g\"\n#&gt;   ..- attr(*, \"labels\")= Named num [1:7] 1 2 3 4 5 6 7\n#&gt;   .. ..- attr(*, \"names\")= chr [1:7] \"January\" \"February\" \"March\" \"April\" ...\n#&gt;  $ procedure: 'dbl' num [1:7368] 1 0 0 1 0 1 1 0 0 0 ...\n#&gt;   ..- attr(*, \"label\")= chr \"Admission procedure\"\n#&gt;   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#&gt;   ..- attr(*, \"labels\")= Named num [1:2] 0 1\n#&gt;   .. ..- attr(*, \"names\")= chr [1:2] \"Old\" \"New\"\n#&gt;  $ satis    : num [1:7368] 4.11 3.32 3.41 3 3.11 ...\n#&gt;   ..- attr(*, \"label\")= chr \"Patient satisfaction score\"\n#&gt;   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#&gt;  - attr(*, \"label\")= chr \"Artificial hospital admission procedure data\"\n\n#select the hospitals for which the new admission procedure will be applied\nnew_procedure_hospitals &lt;- unique(df$hospital[df$procedure == 1])\nnew_procedure_hospitals\n\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18\n\ntreated_data &lt;- df %&gt;% filter(hospital %in% new_procedure_hospitals)\nmean_satisfaction_treated_before &lt;- treated_data %&gt;% filter(month == 3) %&gt;% summarise(mean_satisfaction = mean(satis, na.rm = TRUE)) %&gt;% pull(mean_satisfaction)\nmean_satisfaction_treated_after &lt;- treated_data %&gt;% filter(month == 4) %&gt;% summarise(mean_satisfaction = mean(satis, na.rm = TRUE)) %&gt;% pull(mean_satisfaction)\n\ncontrol_data &lt;- df %&gt;% filter(!hospital %in% new_procedure_hospitals)\nmean_satisfaction_control_before &lt;- control_data %&gt;% filter(month == 3) %&gt;% summarise(mean_satisfaction = mean(satis, na.rm = TRUE)) %&gt;% pull(mean_satisfaction)\nmean_satisfaction_control_after &lt;- control_data %&gt;% filter(month == 4) %&gt;% summarise(mean_satisfaction = mean(satis, na.rm = TRUE)) %&gt;% pull(mean_satisfaction)\n\nDiD_estimate_before &lt;- mean_satisfaction_treated_before - mean_satisfaction_control_before\nDiD_estimate_after &lt;- mean_satisfaction_treated_after - mean_satisfaction_control_after\n\nDiD &lt;- DiD_estimate_after - DiD_estimate_before\ncat(\"Estimated DiD: \", DiD)\n\n#&gt; Estimated DiD:  0.8228153\n\n\n\n\n2 Assignment 2\n\nmodel_01 &lt;- lm(satis ~ procedure + month + hospital, data = df)\nsummary(model_01)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satis ~ procedure + month + hospital, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.3126 -0.6548 -0.0933  0.5555  5.3347 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  3.538024   0.031365 112.801  &lt; 2e-16 ***\n#&gt; procedure    0.886120   0.039143  22.638  &lt; 2e-16 ***\n#&gt; month       -0.004965   0.006392  -0.777 0.437378    \n#&gt; hospital    -0.003731   0.001043  -3.576 0.000351 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9836 on 7364 degrees of freedom\n#&gt; Multiple R-squared:  0.1325, Adjusted R-squared:  0.1321 \n#&gt; F-statistic: 374.8 on 3 and 7364 DF,  p-value: &lt; 2.2e-16\n\nmodel_02 &lt;- lm(satis ~ procedure + as.factor(month) + as.factor(hospital), data = df)\nsummary(model_02)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satis ~ procedure + as.factor(month) + as.factor(hospital), \n#&gt;     data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.1880 -0.4644  0.0067  0.4539  4.2921 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)            3.1716566  0.0562207  56.414  &lt; 2e-16 ***\n#&gt; procedure              0.8479879  0.0342191  24.781  &lt; 2e-16 ***\n#&gt; as.factor(month)2     -0.0096077  0.0292119  -0.329 0.742244    \n#&gt; as.factor(month)3      0.0219686  0.0292119   0.752 0.452050    \n#&gt; as.factor(month)4     -0.0032839  0.0324936  -0.101 0.919504    \n#&gt; as.factor(month)5     -0.0094027  0.0324936  -0.289 0.772305    \n#&gt; as.factor(month)6     -0.0038375  0.0324936  -0.118 0.905990    \n#&gt; as.factor(month)7     -0.0111941  0.0324936  -0.345 0.730478    \n#&gt; as.factor(hospital)2   0.4085664  0.0772418   5.289 1.26e-07 ***\n#&gt; as.factor(hospital)3   0.5336248  0.0793384   6.726 1.88e-11 ***\n#&gt; as.factor(hospital)4   0.2275102  0.0739411   3.077 0.002099 ** \n#&gt; as.factor(hospital)5  -0.1453529  0.0739411  -1.966 0.049360 *  \n#&gt; as.factor(hospital)6   0.4478634  0.0739411   6.057 1.46e-09 ***\n#&gt; as.factor(hospital)7   1.4044164  0.0714559  19.654  &lt; 2e-16 ***\n#&gt; as.factor(hospital)8   0.0718758  0.0763186   0.942 0.346333    \n#&gt; as.factor(hospital)9  -1.5185150  0.0782447 -19.407  &lt; 2e-16 ***\n#&gt; as.factor(hospital)10  1.6828446  0.0772418  21.787  &lt; 2e-16 ***\n#&gt; as.factor(hospital)11  0.2209653  0.0763186   2.895 0.003799 ** \n#&gt; as.factor(hospital)12 -0.0953034  0.0782447  -1.218 0.223256    \n#&gt; as.factor(hospital)13  0.4955931  0.0754658   6.567 5.48e-11 ***\n#&gt; as.factor(hospital)14  0.2330426  0.0793384   2.937 0.003321 ** \n#&gt; as.factor(hospital)15 -0.1444935  0.0793384  -1.821 0.068613 .  \n#&gt; as.factor(hospital)16  1.4142680  0.0772418  18.310  &lt; 2e-16 ***\n#&gt; as.factor(hospital)17  0.4235429  0.0805362   5.259 1.49e-07 ***\n#&gt; as.factor(hospital)18  0.1532761  0.0938164   1.634 0.102346    \n#&gt; as.factor(hospital)19 -0.7453017  0.0811623  -9.183  &lt; 2e-16 ***\n#&gt; as.factor(hospital)20  0.0473874  0.0791140   0.599 0.549207    \n#&gt; as.factor(hospital)21  1.1943370  0.0836232  14.282  &lt; 2e-16 ***\n#&gt; as.factor(hospital)22  0.7993153  0.0823336   9.708  &lt; 2e-16 ***\n#&gt; as.factor(hospital)23  0.7017202  0.0811623   8.646  &lt; 2e-16 ***\n#&gt; as.factor(hospital)24 -0.3081260  0.0866402  -3.556 0.000378 ***\n#&gt; as.factor(hospital)25  0.6464736  0.0927258   6.972 3.40e-12 ***\n#&gt; as.factor(hospital)26  0.2142471  0.0791140   2.708 0.006783 ** \n#&gt; as.factor(hospital)27 -0.3986544  0.0766106  -5.204 2.01e-07 ***\n#&gt; as.factor(hospital)28  0.7119953  0.0836232   8.514  &lt; 2e-16 ***\n#&gt; as.factor(hospital)29  0.2485512  0.0800935   3.103 0.001921 ** \n#&gt; as.factor(hospital)30 -0.1679220  0.0953638  -1.761 0.078304 .  \n#&gt; as.factor(hospital)31  0.5120848  0.0791140   6.473 1.02e-10 ***\n#&gt; as.factor(hospital)32 -0.3233456  0.0800935  -4.037 5.47e-05 ***\n#&gt; as.factor(hospital)33 -0.4539752  0.0791140  -5.738 9.95e-09 ***\n#&gt; as.factor(hospital)34 -0.0004123  0.0746054  -0.006 0.995590    \n#&gt; as.factor(hospital)35  0.3541110  0.0766106   4.622 3.86e-06 ***\n#&gt; as.factor(hospital)36  2.1381425  0.0773811  27.631  &lt; 2e-16 ***\n#&gt; as.factor(hospital)37  0.1404036  0.0927258   1.514 0.130023    \n#&gt; as.factor(hospital)38 -0.0868060  0.0782129  -1.110 0.267093    \n#&gt; as.factor(hospital)39 -0.0234969  0.0823336  -0.285 0.775356    \n#&gt; as.factor(hospital)40  1.1215331  0.0782129  14.339  &lt; 2e-16 ***\n#&gt; as.factor(hospital)41 -0.1497346  0.0766106  -1.954 0.050681 .  \n#&gt; as.factor(hospital)42  0.8811369  0.0850508  10.360  &lt; 2e-16 ***\n#&gt; as.factor(hospital)43 -0.7724325  0.0811623  -9.517  &lt; 2e-16 ***\n#&gt; as.factor(hospital)44  0.0344120  0.0904337   0.381 0.703569    \n#&gt; as.factor(hospital)45 -0.2137495  0.0766106  -2.790 0.005283 ** \n#&gt; as.factor(hospital)46  0.0784915  0.0823336   0.953 0.340452    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.7238 on 7315 degrees of freedom\n#&gt; Multiple R-squared:  0.5333, Adjusted R-squared:  0.5299 \n#&gt; F-statistic: 160.7 on 52 and 7315 DF,  p-value: &lt; 2.2e-16\n\n\nThe key difference between including the variables directly or as a factor is that when being included as a factor, each level/value of the variable is treated as a separate category, as can be seen from the summarised results. Consequently, different effects can be observed for each hospital or month."
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "1 Assignment 1\n\nT_S&lt;-0.2\nT0_S&lt;-0.8\nT_S0&lt;-0.6\nT0_S0&lt;-0.4\nS&lt;-0.3\nS0&lt;-0.7\n\nP_T_S&lt;-T_S * S\nP_T_S0&lt;-T_S0 * S0\nP_T0_S&lt;-T0_S * S\nP_T0_S0&lt;-T0_S0 * S0\n\nprint(P_T_S)\n\n#&gt; [1] 0.06\n\nprint(P_T_S0)\n\n#&gt; [1] 0.42\n\nprint(P_T0_S)\n\n#&gt; [1] 0.24\n\nprint(P_T0_S0)\n\n#&gt; [1] 0.28\n\n\n\n\n2 Assignment 2\n\nWhat is the percentage of customers using all three devices?\n\n0,5%\n\nWhat is the percentage of customers using at least two devices?\n\n0,5% + 3,3% + 7,3% + 8,8% = 19,9%\n\nWhat is the percentage of customers using only one device?\n\n100% - 19,9% = 80,1%\n\n\n\n\n3 Assignment 3\n\nP_A&lt;-0.04\nP_A0&lt;-1-P_A\nP_BA&lt;-0.97\nP_BA0&lt;-0.01\n\nP_B&lt;-P_BA*P_A+P_BA0*P_A0\nP_AB&lt;-(P_BA*P_A)/P_B\nP_A0B&lt;-(P_BA0*P_A0)/P_B\n\nprint(P_B)\n\n#&gt; [1] 0.0484\n\nprint(P_AB)\n\n#&gt; [1] 0.8016529\n\nprint(P_A0B)\n\n#&gt; [1] 0.1983471\n\n\nThese results show that in case the alarm is triggered, there is a possibility of about 19,83% that the product is flawless and a probability of 80,17% that the product is faulty."
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "1 Dimensions\n\ndf &lt;- readRDS(\"data/car_prices.rds\")\ncat(\"The dimensions are \", dim(df), \"\\n\")\n\n#&gt; The dimensions are  181 22\n\n\n\n\n2 Data types\n\nstr(df)\n\n#&gt; Classes 'tbl_df', 'tbl' and 'data.frame':    181 obs. of  22 variables:\n#&gt;  $ aspiration      : chr  \"std\" \"std\" \"std\" \"std\" ...\n#&gt;  $ doornumber      : chr  \"two\" \"two\" \"two\" \"four\" ...\n#&gt;  $ carbody         : chr  \"convertible\" \"convertible\" \"hatchback\" \"sedan\" ...\n#&gt;  $ drivewheel      : chr  \"rwd\" \"rwd\" \"rwd\" \"fwd\" ...\n#&gt;  $ enginelocation  : chr  \"front\" \"front\" \"front\" \"front\" ...\n#&gt;  $ wheelbase       : num  88.6 88.6 94.5 99.8 99.4 ...\n#&gt;  $ carlength       : num  169 169 171 177 177 ...\n#&gt;  $ carwidth        : num  64.1 64.1 65.5 66.2 66.4 66.3 71.4 71.4 71.4 67.9 ...\n#&gt;  $ carheight       : num  48.8 48.8 52.4 54.3 54.3 53.1 55.7 55.7 55.9 52 ...\n#&gt;  $ curbweight      : num  2548 2548 2823 2337 2824 ...\n#&gt;  $ enginetype      : chr  \"dohc\" \"dohc\" \"ohcv\" \"ohc\" ...\n#&gt;  $ cylindernumber  : chr  \"four\" \"four\" \"six\" \"four\" ...\n#&gt;  $ enginesize      : num  130 130 152 109 136 136 136 136 131 131 ...\n#&gt;  $ fuelsystem      : chr  \"mpfi\" \"mpfi\" \"mpfi\" \"mpfi\" ...\n#&gt;  $ boreratio       : num  3.47 3.47 2.68 3.19 3.19 3.19 3.19 3.19 3.13 3.13 ...\n#&gt;  $ stroke          : num  2.68 2.68 3.47 3.4 3.4 3.4 3.4 3.4 3.4 3.4 ...\n#&gt;  $ compressionratio: num  9 9 9 10 8 8.5 8.5 8.5 8.3 7 ...\n#&gt;  $ horsepower      : num  111 111 154 102 115 110 110 110 140 160 ...\n#&gt;  $ peakrpm         : num  5000 5000 5000 5500 5500 5500 5500 5500 5500 5500 ...\n#&gt;  $ citympg         : num  21 21 19 24 18 19 19 19 17 16 ...\n#&gt;  $ highwaympg      : num  27 27 26 30 22 25 25 25 20 22 ...\n#&gt;  $ price           : num  13495 16500 16500 13950 17450 ...\n\n\nThere are two data types: Numbers (“num”) and strings (“chr”).\n\n\n3 Linear regression\n\nmodel &lt;- lm(price ~., data = df)\nsummary(model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\nmin_rpm &lt;- min(df$peakrpm)\nmax_rpm &lt;- max(df$peakrpm)\n\n\n\n4 Regressor: peakrpm\nThe attribute “peakrpm” is of numeric type and can take on values between 4200 and 6600 (within the given dataset). Peak RPM stands for the maximum revolutions per minute the car’s engine will be able to perform. Since the coefficient estimate is positive, the price of the var will increase as the value of “peakrpm” increases. The statistical significance is indicated by the p-value: A small p-value implies a high statistical significance. Since the p-value is rather small for the chosen attribute (0.000108), it is of high statistical significance.\n\n\n5 Seat heating\n\ndf &lt;- df %&gt;%\n  mutate(seat_heating = TRUE)\n\nsummary(df)\n\n#&gt;   aspiration         doornumber          carbody           drivewheel       \n#&gt;  Length:181         Length:181         Length:181         Length:181        \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  enginelocation       wheelbase        carlength        carwidth    \n#&gt;  Length:181         Min.   : 86.60   Min.   :141.1   Min.   :60.30  \n#&gt;  Class :character   1st Qu.: 94.50   1st Qu.:166.3   1st Qu.:64.00  \n#&gt;  Mode  :character   Median : 96.50   Median :173.0   Median :65.40  \n#&gt;                     Mean   : 98.21   Mean   :173.3   Mean   :65.74  \n#&gt;                     3rd Qu.:100.40   3rd Qu.:180.2   3rd Qu.:66.50  \n#&gt;                     Max.   :120.90   Max.   :208.1   Max.   :72.30  \n#&gt;    carheight       curbweight    enginetype        cylindernumber    \n#&gt;  Min.   :47.80   Min.   :1488   Length:181         Length:181        \n#&gt;  1st Qu.:52.00   1st Qu.:2122   Class :character   Class :character  \n#&gt;  Median :53.70   Median :2410   Mode  :character   Mode  :character  \n#&gt;  Mean   :53.58   Mean   :2521                                        \n#&gt;  3rd Qu.:55.50   3rd Qu.:2910                                        \n#&gt;  Max.   :59.80   Max.   :4066                                        \n#&gt;    enginesize     fuelsystem          boreratio         stroke    \n#&gt;  Min.   : 61.0   Length:181         Min.   :2.540   Min.   :2.07  \n#&gt;  1st Qu.: 98.0   Class :character   1st Qu.:3.150   1st Qu.:3.08  \n#&gt;  Median :120.0   Mode  :character   Median :3.310   Median :3.23  \n#&gt;  Mean   :127.1                      Mean   :3.325   Mean   :3.23  \n#&gt;  3rd Qu.:141.0                      3rd Qu.:3.590   3rd Qu.:3.40  \n#&gt;  Max.   :326.0                      Max.   :3.940   Max.   :4.17  \n#&gt;  compressionratio   horsepower       peakrpm        citympg     \n#&gt;  Min.   : 7.000   Min.   : 48.0   Min.   :4200   Min.   :13.00  \n#&gt;  1st Qu.: 8.500   1st Qu.: 70.0   1st Qu.:4800   1st Qu.:19.00  \n#&gt;  Median : 9.000   Median : 95.0   Median :5200   Median :24.00  \n#&gt;  Mean   : 8.848   Mean   :106.2   Mean   :5182   Mean   :24.85  \n#&gt;  3rd Qu.: 9.400   3rd Qu.:116.0   3rd Qu.:5500   3rd Qu.:30.00  \n#&gt;  Max.   :11.500   Max.   :288.0   Max.   :6600   Max.   :49.00  \n#&gt;    highwaympg        price       seat_heating  \n#&gt;  Min.   :16.00   Min.   : 5118   Mode:logical  \n#&gt;  1st Qu.:25.00   1st Qu.: 7609   TRUE:181      \n#&gt;  Median :30.00   Median : 9980                 \n#&gt;  Mean   :30.48   Mean   :12999                 \n#&gt;  3rd Qu.:34.00   3rd Qu.:16430                 \n#&gt;  Max.   :54.00   Max.   :45400\n\nmodel &lt;- lm(price ~., data = df)\nsummary(model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; seat_heatingTRUE             NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nThe output results in an error, since the model matrix will be singular (all values are the same; “TRUE”) and have no inverse. It obviously would not have any impact on the price either, since it is constant across the entire dataset."
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "As can be observed from the code below, the results do not appear to be very sensitive to a reduction in the bandwidth. The local average treatment effect changes from 7.99 to 7.36, which is a small change considering the bandwidth was halved (a relative change of 8%). However, the slope of the average treatment effect appears to be steeper than before.\n\ndf &lt;- readRDS(\"data/coupon.rds\")\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-2.5, 2.5)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n#&gt; [1] \"LATE: 7.36\"\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\nmin_y &lt;- min(df_bw$purchase_after)\nmax_y &lt;- max(df_bw$purchase_after)\n\n# Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- \n  ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) +\n  geom_vline(xintercept = c0, color = \"blue\", linewidth = 2) +\n  geom_point(alpha = 0.4, size = 1) +\n  geom_smooth(data = df_bw_below, method = \"lm\", se = F, linewidth = 2) +\n  geom_smooth(data = df_bw_above, method = \"lm\", se = F, linewidth = 2) +\n  geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0),\n               linetype = \"dotted\", color = \"red\") +\n  geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1),\n               linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = c0+2, y = mean(c(y1, y0)-2),\n           label = sprintf(\"Difference: %.2f\", (y1 - y0)),\n           color = \"green\", fontface = 2) +\n  scale_y_continuous(limits = c(min_y, max_y)) + \n  scale_color_discrete(labels = c(\"No coupon\", \"Coupon\")) +\n  xlab(\"Days since last purchase\") +\n  ylab(\"Purchase after coupon assignment\") +\n  theme(legend.title = element_blank())\ndep_var_bw\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nDoubling the bandwidth increases the LATE by a factor of 1,19. The average treatment effect appears almost constant aside from the jump at the cut-off point.\n\ndf &lt;- readRDS(\"data/coupon.rds\")\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-10, 10)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n#&gt; [1] \"LATE: 9.51\"\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\nmin_y &lt;- min(df_bw$purchase_after)\nmax_y &lt;- max(df_bw$purchase_after)\n\n# Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- \n  ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) +\n  geom_vline(xintercept = c0, color = \"blue\", linewidth = 2) +\n  geom_point(alpha = 0.4, size = 1) +\n  geom_smooth(data = df_bw_below, method = \"lm\", se = F, linewidth = 2) +\n  geom_smooth(data = df_bw_above, method = \"lm\", se = F, linewidth = 2) +\n  geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0),\n               linetype = \"dotted\", color = \"red\") +\n  geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1),\n               linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = c0+2, y = mean(c(y1, y0)-2),\n           label = sprintf(\"Difference: %.2f\", (y1 - y0)),\n           color = \"green\", fontface = 2) +\n  scale_y_continuous(limits = c(min_y, max_y)) + \n  scale_color_discrete(labels = c(\"No coupon\", \"Coupon\")) +\n  xlab(\"Days since last purchase\") +\n  ylab(\"Purchase after coupon assignment\") +\n  theme(legend.title = element_blank())\ndep_var_bw\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/09_iv.html#stable-unit-treatment-value-assumption",
    "href": "content/01_journal/09_iv.html#stable-unit-treatment-value-assumption",
    "title": "Instrumental Variables",
    "section": "3.1 Stable unit treatment value assumption",
    "text": "3.1 Stable unit treatment value assumption\nThe stable unit treatment value assumption is met, since the treatment for one user (usage of the new feature) does not affect the choices of another user."
  },
  {
    "objectID": "content/01_journal/09_iv.html#independence-assumption",
    "href": "content/01_journal/09_iv.html#independence-assumption",
    "title": "Instrumental Variables",
    "section": "3.2 Independence assumption",
    "text": "3.2 Independence assumption\nSince the instrument (encouragement popup) is assigned to users randomly, it makes sense intuitively that there is no factor that influences both the instrument and the treatment (usage of new feature) or outcome (time spent on app)."
  },
  {
    "objectID": "content/01_journal/09_iv.html#instrument-relevance",
    "href": "content/01_journal/09_iv.html#instrument-relevance",
    "title": "Instrumental Variables",
    "section": "3.3 Instrument relevance",
    "text": "3.3 Instrument relevance\nThe correlation of Z and D is checked using the “first stage”:\n\nfirst_stage &lt;- lm(used_ftr ~ rand_enc, data = df)\nsummary(first_stage)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = used_ftr ~ rand_enc, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -0.5071 -0.3062 -0.3062  0.4929  0.6938 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 0.306164   0.006851   44.69   &lt;2e-16 ***\n#&gt; rand_enc    0.200940   0.009624   20.88   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.4811 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.04178,    Adjusted R-squared:  0.04169 \n#&gt; F-statistic:   436 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\nSince the p-value is very small, the instrument (encouragement) is highly significant."
  },
  {
    "objectID": "content/01_journal/09_iv.html#monotonicity-assumption",
    "href": "content/01_journal/09_iv.html#monotonicity-assumption",
    "title": "Instrumental Variables",
    "section": "3.4 Monotonicity assumption",
    "text": "3.4 Monotonicity assumption\nThe monotonicity assumption is checked using the given framework:\n\nmonotonicity_check &lt;- df %&gt;%\n  mutate(observation_unit = case_when(\n    (rand_enc == 1 & used_ftr == 1) ~ \"Complier\",\n    (rand_enc == 1 & used_ftr == 0) ~ \"Defier\",\n    (rand_enc == 0 & used_ftr == 0) ~ \"Never taker\",\n    (rand_enc == 0 & used_ftr == 1) ~ \"Always taker\"\n  ))\n\n\ntable(monotonicity_check$observation_unit)\n\n#&gt; \n#&gt; Always taker     Complier       Defier  Never taker \n#&gt;         1510         2570         2498         3422\n\n\nThere is about the same number of compliers and defiers. This raises questions about the validity of the instrument. I would argue that the chosen instrument is not a very suitable estimation procedure for this application."
  },
  {
    "objectID": "content/01_journal/10_rdd.html#results-with-half-the-bandwidth",
    "href": "content/01_journal/10_rdd.html#results-with-half-the-bandwidth",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "As can be observed from the code below, the results do not appear to be very sensitive to a reduction in the bandwidth. The local average treatment effect changes from 7.99 to 7.36, which is a small change considering the bandwidth was halved (a relative change of 8%). However, the slope of the average treatment effect appears to be steeper than before.\n\ndf &lt;- readRDS(\"data/coupon.rds\")\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-2.5, 2.5)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n#&gt; [1] \"LATE: 7.36\"\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\nmin_y &lt;- min(df_bw$purchase_after)\nmax_y &lt;- max(df_bw$purchase_after)\n\n# Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- \n  ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) +\n  geom_vline(xintercept = c0, color = \"blue\", linewidth = 2) +\n  geom_point(alpha = 0.4, size = 1) +\n  geom_smooth(data = df_bw_below, method = \"lm\", se = F, linewidth = 2) +\n  geom_smooth(data = df_bw_above, method = \"lm\", se = F, linewidth = 2) +\n  geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0),\n               linetype = \"dotted\", color = \"red\") +\n  geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1),\n               linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = c0+2, y = mean(c(y1, y0)-2),\n           label = sprintf(\"Difference: %.2f\", (y1 - y0)),\n           color = \"green\", fontface = 2) +\n  scale_y_continuous(limits = c(min_y, max_y)) + \n  scale_color_discrete(labels = c(\"No coupon\", \"Coupon\")) +\n  xlab(\"Days since last purchase\") +\n  ylab(\"Purchase after coupon assignment\") +\n  theme(legend.title = element_blank())\ndep_var_bw\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/10_rdd.html#results-with-twice-the-bandwidth",
    "href": "content/01_journal/10_rdd.html#results-with-twice-the-bandwidth",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Doubling the bandwidth increases the LATE by a factor of 1,19. The average treatment effect appears almost constant aside from the jump at the cut-off point.\n\ndf &lt;- readRDS(\"data/coupon.rds\")\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-10, 10)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n#&gt; [1] \"LATE: 9.51\"\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\nmin_y &lt;- min(df_bw$purchase_after)\nmax_y &lt;- max(df_bw$purchase_after)\n\n# Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- \n  ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) +\n  geom_vline(xintercept = c0, color = \"blue\", linewidth = 2) +\n  geom_point(alpha = 0.4, size = 1) +\n  geom_smooth(data = df_bw_below, method = \"lm\", se = F, linewidth = 2) +\n  geom_smooth(data = df_bw_above, method = \"lm\", se = F, linewidth = 2) +\n  geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0),\n               linetype = \"dotted\", color = \"red\") +\n  geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1),\n               linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = c0+2, y = mean(c(y1, y0)-2),\n           label = sprintf(\"Difference: %.2f\", (y1 - y0)),\n           color = \"green\", fontface = 2) +\n  scale_y_continuous(limits = c(min_y, max_y)) + \n  scale_color_discrete(labels = c(\"No coupon\", \"Coupon\")) +\n  xlab(\"Days since last purchase\") +\n  ylab(\"Purchase after coupon assignment\") +\n  theme(legend.title = element_blank())\ndep_var_bw\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  }
]